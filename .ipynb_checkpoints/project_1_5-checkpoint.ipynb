{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd11da2a",
   "metadata": {},
   "source": [
    "# Project 1, Part 5, Data Visualization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b052db7c",
   "metadata": {},
   "source": [
    "# Included Modules and Packages\n",
    "\n",
    "Code cell containing your includes for modules and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a400eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "import gmaps\n",
    "import gmaps.geojson_geometries\n",
    "\n",
    "from geographiclib.geodesic import Geodesic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d954ac75",
   "metadata": {},
   "source": [
    "# Supporting code\n",
    "\n",
    "Code cells containing any supporting code, such as connecting to the database, any functions, etc.  Remember you can use any code from the labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa124e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# function to run a select query and return rows in a pandas dataframe\n",
    "# pandas puts all numeric values from postgres to float\n",
    "# if it will fit in an integer, change it to integer\n",
    "#\n",
    "\n",
    "def my_select_query_pandas(query, rollback_before_flag, rollback_after_flag):\n",
    "    \"function to run a select query and return rows in a pandas dataframe\"\n",
    "    \n",
    "    if rollback_before_flag:\n",
    "        connection.rollback()\n",
    "    \n",
    "    df = pd.read_sql_query(query, connection)\n",
    "    \n",
    "    if rollback_after_flag:\n",
    "        connection.rollback()\n",
    "    \n",
    "    # fix the float columns that really should be integers\n",
    "    \n",
    "    for column in df:\n",
    "    \n",
    "        if df[column].dtype == \"float64\":\n",
    "\n",
    "            fraction_flag = False\n",
    "\n",
    "            for value in df[column].values:\n",
    "                \n",
    "                if not np.isnan(value):\n",
    "                    if value - math.floor(value) != 0:\n",
    "                        fraction_flag = True\n",
    "\n",
    "            if not fraction_flag:\n",
    "                df[column] = df[column].astype('Int64')\n",
    "    \n",
    "    return(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c00f0670",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(\n",
    "    user = \"postgres\",\n",
    "    password = \"ucb\",\n",
    "    host = \"postgres\",\n",
    "    port = \"5432\",\n",
    "    database = \"postgres\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d55fbbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'gmap_api_key.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_418/2601028655.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gmap_api_key.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmy_api_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgmaps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_api_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gmap_api_key.txt'"
     ]
    }
   ],
   "source": [
    "f = open('gmap_api_key.txt', 'r')\n",
    "my_api_key = f.read()\n",
    "f.close()\n",
    "\n",
    "gmaps.configure(api_key=my_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649af216",
   "metadata": {},
   "source": [
    "# 1.5 Example of a Data Visualization created using Python\n",
    "\n",
    "The data science team would like for you to create an example of a data visualization using Python from data in a Pandas dataframe containing data from an SQL query.\n",
    "\n",
    "Write 1 and only 1 query.  Note that the query may have as many subqueries, including \"with\" clauses, as you wish.  Any query of your choosing.  You can write a query from scratch.  You can use a query from a previous problem in this project.  You can use a query from the labs.  The idea is to come up with a query whose resulting data will make for an excellent quality data visualization. \n",
    "\n",
    "Ensure that when you check this Juptyer Notebook into GitHub that the query results in the Pandas dataframe are clearly visible in GitHub.  Note: When a query result has a large number of rows, Pandas will only display the first 5 rows, a row with ellipses, and the last 5 rows. This is ok.\n",
    "\n",
    "Once you have the data in a Pandas dataframe, you may write as much Python code and use as many code cells as you wish to produce the data visualization.\n",
    "\n",
    "You may only use Python modules that are currently installed in the Anaconda Docker container.  You may not install additional modules or any other software.\n",
    "\n",
    "All work must be done in Docker in your VM in AWS.  You may not use any external data visualization systems, such as Tableau, etc.\n",
    "\n",
    "You may use any code from the labs to pattern your code after, however for the data visualization, you cannot wholesale copy a data visualization from the labs.\n",
    "\n",
    "Ensure that it is properly titled, including titles for axes if present.\n",
    "\n",
    "Ensure that when you check this Juptyer Notebook into GitHub that the data visualization is clearly visible.  \n",
    "\n",
    "If you want to use Google Maps for your data visualization, this is fine, however, the image will not show up in GitHub.  So, just save the image to an image file, include it in the repo, and add a markdown cell to display the image file. Also with Google Maps, do NOT check gmap_api_key.txt into GitHub for security reasons.  If the grader needs to run it, they will supply their own gmap_api_key.txt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e736b58",
   "metadata": {},
   "source": [
    "## 1.5.1 Project Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c8e0a0",
   "metadata": {},
   "source": [
    "In this project, we are analyzing the relationship between Acme Gourmet Meals (AGM) and its customers. More specifically, we are interested in visualizing patterns of out-of-city and out-of-state customers based on their transactions.\n",
    "\n",
    "To accomplish this, we are conducting two types of analyses. First, we are creating visualizations using seaborn and matplotlib to understand the customer's spending patterns in different locations. Second, we are plotting the geographical connections between the customers and the stores using gmaps for a more intuitive geographical representation.\n",
    "\n",
    "The approach begins with a SQL query to organize and prepare the data, followed by several Python blocks to visualize the data. The end goal is to gain insights into customer behaviors that can help the store optimize its operations and marketing strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc7b0f0",
   "metadata": {},
   "source": [
    "## 1.5.2 Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e591c8a",
   "metadata": {},
   "source": [
    "In this section, we begin by creating a temporary SQL table 'store_sales_master'. This table contains comprehensive information about the customers, their transactions, and their geographical connection to the stores. It allows us to derive metrics such as 'out_of_city' and 'out_of_state', which indicate whether a customer lives in a different city or state from the store. This code block forms the backbone of our analysis, as the data obtained from this query will be used in all subsequent visualizations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc31d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "rollback_before_flag = True\n",
    "rollback_after_flag = True\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "/* Creating a temp table called 'store_sales_master' */\n",
    "with store_sales_master as (\n",
    "    /* Inside this temp table, selecting the required columns and calculating \n",
    "       the number of transactions, items bought, and amount spent per store */\n",
    "    select \n",
    "        c.zip as customer_zip,\n",
    "        zc.city as customer_city,\n",
    "        zc.state as customer_state,\n",
    "        zc.latitude as customer_latitude,\n",
    "        zc.longitude as customer_longitude,\n",
    "        s.store_id,\n",
    "        st.city as store_city,\n",
    "        st.state as store_state,\n",
    "        zc_store.latitude as store_latitude,\n",
    "        zc_store.longitude as store_longitude,\n",
    "        count(distinct s.sale_id) as total_transactions, \n",
    "        sum(li.quantity) as total_items_bought, \n",
    "        sum(s.total_amount) as total_amount_spent,\n",
    "        /* Adding the 'out_of_city' column */\n",
    "        case \n",
    "            when zc.state = st.state and zc.city != st.city then 'Yes' \n",
    "            else 'No' \n",
    "        end as out_of_city,\n",
    "        /* Adding the 'out_of_state' column */\n",
    "        case \n",
    "            when zc.state != st.state then 'Yes' \n",
    "            else 'No' \n",
    "        end as out_of_state\n",
    "    from \n",
    "        customers c\n",
    "    /* Joining with 'sales' table on 'customer_id' */\n",
    "    join \n",
    "        sales s on c.customer_id = s.customer_id\n",
    "    /* Joining with 'line_items' table on 'sale_id' and 'store_id' */\n",
    "    join \n",
    "        line_items li on s.sale_id = li.sale_id and s.store_id = li.store_id\n",
    "    /* Joining with 'stores' table on 'store_id' */\n",
    "    join \n",
    "        stores st on s.store_id = st.store_id\n",
    "    /* Joining with 'zip_codes' table to compare customer zip with store city zip and to get the customer city and state */\n",
    "    join \n",
    "        zip_codes zc on c.zip = zc.zip\n",
    "    /* Joining with 'zip_codes' table again to get store city zip and to get the store city latitude and longitude */\n",
    "    join\n",
    "        zip_codes zc_store on st.zip = zc_store.zip\n",
    "    /* Grouping by 'customer_zip', 'store_id', 'store_city', 'store_state', 'customer_city', 'customer_state' */\n",
    "    group by \n",
    "        c.zip, \n",
    "        zc.city,\n",
    "        zc.state,\n",
    "        zc.latitude,\n",
    "        zc.longitude,\n",
    "        s.store_id, \n",
    "        st.city, \n",
    "        st.state,\n",
    "        zc_store.latitude,\n",
    "        zc_store.longitude,\n",
    "        zc.zip\n",
    ")\n",
    "\n",
    "/* Now, selecting the computed metrics and the newly created columns 'out_of_city' and 'out_of_state' from 'store_sales_master' temp table */\n",
    "select \n",
    "    customer_zip,\n",
    "    customer_city,\n",
    "    customer_state,\n",
    "    customer_latitude,\n",
    "    customer_longitude,\n",
    "    store_id,\n",
    "    store_city,\n",
    "    store_state,\n",
    "    store_latitude,\n",
    "    store_longitude,\n",
    "    total_transactions, \n",
    "    round(total_items_bought / total_transactions, 2) as avg_items_per_transaction, \n",
    "    round(total_amount_spent / total_transactions, 2) as avg_amount_per_transaction,\n",
    "    out_of_city,\n",
    "    out_of_state\n",
    "from \n",
    "    store_sales_master;\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df = my_select_query_pandas(query, rollback_before_flag, rollback_after_flag)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636191e8",
   "metadata": {},
   "source": [
    "## 1.5.3 Visualizing Customer Transactions|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2257b36",
   "metadata": {},
   "source": [
    "In the next section, we move into the visualization phase. Here, we generate a grid of 2x2 subplots using matplotlib and seaborn to showcase:\n",
    "\n",
    "* The number of out-of-city customers per state.\n",
    "* The average amount spent per transaction for out-of-city and in-city customers by state.\n",
    "* The relationship between the average items bought and the average amount spent per transaction.\n",
    "* The average items bought per transaction for out-of-city and in-city customers by state.\n",
    "\n",
    "These visualizations provide a clear understanding of customer behavior patterns, differences between in-city and out-of-city customers, and transaction characteristics in different states.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a71b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"talk\")  # Increases the size of the labels, ticks and title\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(20, 20)) \n",
    "\n",
    "# Query 1\n",
    "sns.countplot(data=df, x='customer_state', hue='out_of_city', ax=ax[0, 0], palette=['#333333', 'lightgray'])\n",
    "ax[0, 0].set_title('Number of Out-Of-City Customers Per State', fontsize=20)\n",
    "ax[0, 0].set_xlabel('State', fontsize=18)\n",
    "ax[0, 0].set_ylabel('Number of Customers', fontsize=18)\n",
    "ax[0, 0].legend(fontsize=14)\n",
    "\n",
    "# Query 2\n",
    "sns.barplot(data=df, x='customer_state', y='avg_amount_per_transaction', hue='out_of_city', ax=ax[0, 1], palette=['#333333', 'lightgray'])\n",
    "ax[0, 1].set_title('Average Amount Per Transaction for Out-Of-City and In-City Customers by State', fontsize=20)\n",
    "ax[0, 1].set_xlabel('State', fontsize=18)\n",
    "ax[0, 1].set_ylabel('Average Amount Per Transaction', fontsize=18)\n",
    "ax[0, 1].legend(fontsize=14)\n",
    "\n",
    "# Query 3\n",
    "sns.scatterplot(data=df, x='avg_items_per_transaction', y='avg_amount_per_transaction', hue='out_of_city', ax=ax[1, 0], palette=['#333333', 'lightgray'])\n",
    "ax[1, 0].set_title('Relationship between Average Items and Average Amount per Transaction', fontsize=20)\n",
    "ax[1, 0].set_xlabel('Average Items Per Transaction', fontsize=18)\n",
    "ax[1, 0].set_ylabel('Average Amount Per Transaction', fontsize=18)\n",
    "ax[1, 0].legend(fontsize=14)\n",
    "\n",
    "# Query 4\n",
    "sns.barplot(data=df, x='customer_state', y='avg_items_per_transaction', hue='out_of_city', ax=ax[1, 1], palette=['#333333', 'lightgray'])\n",
    "ax[1, 1].set_title('Average Items Per Transaction for Out-Of-City and In-City Customers by State', fontsize=20)\n",
    "ax[1, 1].set_xlabel('State', fontsize=18)\n",
    "ax[1, 1].set_ylabel('Average Items Per Transaction', fontsize=18)\n",
    "ax[1, 1].legend(fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c6809b",
   "metadata": {},
   "source": [
    "#### Image Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f77d164",
   "metadata": {},
   "source": [
    "<img src=\"1.png\" alt=\"Image title\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250b94c5",
   "metadata": {},
   "source": [
    "* The number of out-of-city customers per state.\n",
    "    > This is an interseting insight in that there are more customers outside the city where the store is located. This, along with the 4th chart helps us understand the catchment area (so to speak) for the store and the distance people are willing to drive\n",
    "* The average amount spent per transaction for out-of-city and in-city customers by state.\n",
    "    > Out of city customers tend to spend more per transaction than otherwise\n",
    "* The relationship between the average items bought and the average amount spent per transaction.\n",
    "    > We expect somewhat of a linear plot for this, which is validated by the chart.\n",
    "* The average items bought per transaction for out-of-city and in-city customers by state.\n",
    "    > The average number of items per transaction is higher than what we assumed initially"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569b33b7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0869c209",
   "metadata": {},
   "source": [
    "## Customer-Store Geographical Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3ce2a4",
   "metadata": {},
   "source": [
    "Finally, we leverage the gmaps library to visualize the geographical connections between customers and stores. We focus on the five cities where the stores are located. For each city, we create a separate map showing lines connecting the store in that city to its customers. Each city gets a unique color for its lines for easier identification. This visualization allows us to see the geographical spread of the customers for each store and understand the extent of out-of-city customer presence.\n",
    "\n",
    "Please note some generalizations done in the master query -- rather than be inundated with very single transaction, this documents takes an aggregate view and is focused more on the location (ie zip codes) where the customers are located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95173475",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_cities = {\n",
    "    1: {\"name\": \"Berkeley\", \"center\": (37.8555, -122.2604), \"zoom\": 9, \"color\": \"#006400\"},\n",
    "    2: {\"name\": \"Seattle\", \"center\": (47.6114, -122.3214), \"zoom\": 9, \"color\": \"#8B4513\"},\n",
    "    3: {\"name\": \"Dallas\", \"center\": (32.7958, -96.8015), \"zoom\": 9, \"color\": \"#B22222\"},\n",
    "    4: {\"name\": \"Miami\", \"center\": (25.772, -80.1891), \"zoom\": 9, \"color\": \"#8A2BE2\"},\n",
    "    5: {\"name\": \"Nashville\", \"center\": (36.1568, -86.7881), \"zoom\": 9, \"color\": \"#20B2AA\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7929c2",
   "metadata": {},
   "source": [
    "### Berkeley Store: Customer Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af89504b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "store_id = 1\n",
    "info = store_cities[store_id]\n",
    "df_store = df[df['store_id'] == store_id]\n",
    "\n",
    "lines = []\n",
    "for idx, row in df_store.iterrows():\n",
    "    customer_location = (row['customer_latitude'], row['customer_longitude'])\n",
    "    store_location = (row['store_latitude'], row['store_longitude'])\n",
    "    lines.append(gmaps.Line(start=customer_location, end=store_location, stroke_weight=1, stroke_color=info['color']))\n",
    "\n",
    "drawing = gmaps.drawing_layer(features=lines)\n",
    "fig = gmaps.figure(center=info[\"center\"], zoom_level=info[\"zoom\"])\n",
    "fig.add_layer(drawing)\n",
    "\n",
    "# Display the figure\n",
    "print(f\"Customer connections for Store in {info['name']}:\")\n",
    "display(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a282589",
   "metadata": {},
   "source": [
    "#### Image Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c761c845",
   "metadata": {},
   "source": [
    "<img src=\"2.png\" alt=\"Image title\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56afdb6",
   "metadata": {},
   "source": [
    "### Seattle Store: Customer Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9878d12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "store_id = 2\n",
    "info = store_cities[store_id]\n",
    "df_store = df[df['store_id'] == store_id]\n",
    "\n",
    "lines = []\n",
    "for idx, row in df_store.iterrows():\n",
    "    customer_location = (row['customer_latitude'], row['customer_longitude'])\n",
    "    store_location = (row['store_latitude'], row['store_longitude'])\n",
    "    lines.append(gmaps.Line(start=customer_location, end=store_location, stroke_weight=1, stroke_color=info['color']))\n",
    "\n",
    "drawing = gmaps.drawing_layer(features=lines)\n",
    "fig = gmaps.figure(center=info[\"center\"], zoom_level=info[\"zoom\"])\n",
    "fig.add_layer(drawing)\n",
    "\n",
    "# Display the figure\n",
    "print(f\"Customer connections for Store in {info['name']}:\")\n",
    "display(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4e61ed",
   "metadata": {},
   "source": [
    "#### Image Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b562d6",
   "metadata": {},
   "source": [
    "<img src=\"3.png\" alt=\"Image title\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afe9d67",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb47c725",
   "metadata": {},
   "source": [
    "### Dallas Store: Customer Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7a5477",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_id = 3\n",
    "info = store_cities[store_id]\n",
    "df_store = df[df['store_id'] == store_id]\n",
    "\n",
    "lines = []\n",
    "for idx, row in df_store.iterrows():\n",
    "    customer_location = (row['customer_latitude'], row['customer_longitude'])\n",
    "    store_location = (row['store_latitude'], row['store_longitude'])\n",
    "    lines.append(gmaps.Line(start=customer_location, end=store_location, stroke_weight=1, stroke_color=info['color']))\n",
    "\n",
    "drawing = gmaps.drawing_layer(features=lines)\n",
    "fig = gmaps.figure(center=info[\"center\"], zoom_level=info[\"zoom\"])\n",
    "fig.add_layer(drawing)\n",
    "\n",
    "# Display the figure\n",
    "print(f\"Customer connections for Store in {info['name']}:\")\n",
    "display(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21a5a8b",
   "metadata": {},
   "source": [
    "#### Image Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c146a59",
   "metadata": {},
   "source": [
    "<img src=\"4.png\" alt=\"Image title\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11698f4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7cd855",
   "metadata": {},
   "source": [
    "### Miami Store: Customer Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9609ce8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "store_id = 4\n",
    "info = store_cities[store_id]\n",
    "df_store = df[df['store_id'] == store_id]\n",
    "\n",
    "lines = []\n",
    "for idx, row in df_store.iterrows():\n",
    "    customer_location = (row['customer_latitude'], row['customer_longitude'])\n",
    "    store_location = (row['store_latitude'], row['store_longitude'])\n",
    "    lines.append(gmaps.Line(start=customer_location, end=store_location, stroke_weight=1, stroke_color=info['color']))\n",
    "\n",
    "drawing = gmaps.drawing_layer(features=lines)\n",
    "fig = gmaps.figure(center=info[\"center\"], zoom_level=info[\"zoom\"])\n",
    "fig.add_layer(drawing)\n",
    "\n",
    "# Display the figure\n",
    "print(f\"Customer connections for Store in {info['name']}:\")\n",
    "display(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfb02c5",
   "metadata": {},
   "source": [
    "#### Image Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314236e0",
   "metadata": {},
   "source": [
    "<img src=\"5.png\" alt=\"Image title\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa129ad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d53bc6",
   "metadata": {},
   "source": [
    "### Nashville Store: Customer Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f41f960",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_id = 5\n",
    "info = store_cities[store_id]\n",
    "df_store = df[df['store_id'] == store_id]\n",
    "\n",
    "lines = []\n",
    "for idx, row in df_store.iterrows():\n",
    "    customer_location = (row['customer_latitude'], row['customer_longitude'])\n",
    "    store_location = (row['store_latitude'], row['store_longitude'])\n",
    "    lines.append(gmaps.Line(start=customer_location, end=store_location, stroke_weight=1, stroke_color=info['color']))\n",
    "\n",
    "drawing = gmaps.drawing_layer(features=lines)\n",
    "fig = gmaps.figure(center=info[\"center\"], zoom_level=info[\"zoom\"])\n",
    "fig.add_layer(drawing)\n",
    "\n",
    "# Display the figure\n",
    "print(f\"Customer connections for Store in {info['name']}:\")\n",
    "display(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d067dd4e",
   "metadata": {},
   "source": [
    "#### Image Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27355f04",
   "metadata": {},
   "source": [
    "<img src=\"6.png\" alt=\"Image title\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e69a82",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425ffec1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598e1a41",
   "metadata": {},
   "source": [
    "## Appendix: Supplemental Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff8aabf",
   "metadata": {},
   "source": [
    "### Store Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c05d7b",
   "metadata": {},
   "source": [
    "> This is a general map showing the greographic distribution of the stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2811d504",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "store_locations = df[['store_latitude', 'store_longitude']]\n",
    "store_layer = gmaps.marker_layer(store_locations)\n",
    "fig = gmaps.figure()\n",
    "fig.add_layer(store_layer)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc37d214",
   "metadata": {},
   "source": [
    "#### Image Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc1b08f",
   "metadata": {},
   "source": [
    "<img src=\"7.png\" alt=\"Image title\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e490996f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4f88c",
   "metadata": {},
   "source": [
    "### Heatmap of Customer Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5591da59",
   "metadata": {},
   "source": [
    "> This can help us understand the geographic distribution of your customers. If the heatmap is denser around your store locations, that suggests your customers are mostly local\n",
    ">> However, since we have aggregate custoemr information, this chart is indicative only and not definitive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d6b1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "customer_locations = df[['customer_latitude', 'customer_longitude']]\n",
    "heatmap_layer = gmaps.heatmap_layer(customer_locations)\n",
    "fig = gmaps.figure()\n",
    "fig.add_layer(heatmap_layer)\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b44778",
   "metadata": {},
   "source": [
    "#### Image Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf35904",
   "metadata": {},
   "source": [
    "<img src=\"8.png\" alt=\"Image title\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5f90e3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741669b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
